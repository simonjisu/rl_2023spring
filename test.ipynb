{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from src.maxent_irl_gridworld import main, run_maxent_irl\n",
    "\n",
    "PARSER = argparse.ArgumentParser(description=None)\n",
    "PARSER.add_argument('-hei', '--height', default=5, type=int, help='height of the gridworld')\n",
    "PARSER.add_argument('-wid', '--width', default=5, type=int, help='width of the gridworld')\n",
    "PARSER.add_argument('-g', '--gamma', default=0.8, type=float, help='discount factor')\n",
    "PARSER.add_argument('-a', '--act_random', default=0.3, type=float, help='probability of acting randomly')\n",
    "PARSER.add_argument('-t', '--n_trajs', default=100, type=int, help='number of expert trajectories')\n",
    "PARSER.add_argument('-it', '--init_n_trajs', default=1, type=int, help='number of expert trajectories')\n",
    "PARSER.add_argument('-l', '--l_traj', default=20, type=int, help='length of expert trajectory')\n",
    "PARSER.add_argument('--rand_start', dest='rand_start', action='store_true', help='when sampling trajectories, randomly pick start positions')\n",
    "PARSER.add_argument('--no-rand_start', dest='rand_start',action='store_false', help='when sampling trajectories, fix start positions')\n",
    "PARSER.set_defaults(rand_start=False)\n",
    "PARSER.add_argument('-lr', '--learning_rate', default=0.01, type=float, help='learning rate')\n",
    "PARSER.add_argument('-ni', '--n_iters', default=20, type=int, help='number of iterations')\n",
    "PARSER.add_argument('-act', '--active', action='store_true', help='active learning setting')  # store true\n",
    "PARSER.add_argument('-al', '--alpha', default=1.0, type=float, help='temperature parameter for value iteration')\n",
    "PARSER.add_argument('-nq', '--n_query', default=1, type=int, help='number of queries to the expert(n_demonstrations)')\n",
    "PARSER.add_argument('-rm', '--r_max', default=1, type=int, help='maximum reward value')\n",
    "\n",
    "def parse_args_str(args_str):\n",
    "    args = PARSER.parse_args(args_str.split())\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(height=5, width=5, gamma=0.9, act_random=0.3, n_trajs=20, init_n_trajs=1, l_traj=5, rand_start=False, learning_rate=0.01, n_iters=50, active=True, alpha=0.1, n_query=1, r_max=1)\n",
      "[INFO] Initialize Grid World\n",
      "[INFO] Getting ground truth values and policy via value teration\n",
      "[INFO] Initialize trajectories\n",
      "[INFO] Trajectory length(Include inital starting point) = 6, First trajectories.\n",
      "[Step(cur_state=23, action=2, next_state=23, reward=0.0, done=False), Step(cur_state=23, action=2, next_state=24, reward=0.0, done=False), Step(cur_state=24, action=2, next_state=24, reward=1.0, done=False), Step(cur_state=24, action=0, next_state=24, reward=1.0, done=False), Step(cur_state=24, action=0, next_state=24, reward=1.0, done=False), Step(cur_state=24, action=0, next_state=24, reward=1.0, done=False)]\n",
      "[INFO] Start Learning\n",
      "[INFO - 00001 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00001 ] Finite Policy Iteration\n",
      "[INFO - 00001 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[3.23998957 3.17531132 2.27114149 1.96177135 1.59588763]\n",
      " [3.54047417 2.77117114 2.51365295 1.89495221 1.2941986 ]\n",
      " [3.29378265 2.64719947 2.51164229 2.09897707 1.30977529]\n",
      " [2.31145574 2.27545766 2.18863457 1.91361679 1.34658305]\n",
      " [1.75363147 1.51934309 1.42608092 1.35047199 1.67966641]]\n",
      "[INFO - 00001 ] Generating a new demonstrations from (1, 0)\n",
      "[INFO - 00002 ] Policy evaluation\n",
      "[INFO - 00002 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00002 ] Finite Policy Iteration\n",
      "[INFO - 00002 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[2.5191765  2.22803603 3.35936233 3.19173971 2.67262573]\n",
      " [2.58984678 3.60619268 3.81356695 3.26712874 2.42676509]\n",
      " [3.65262201 4.04954627 3.09135852 3.2737466  2.46279311]\n",
      " [3.52741877 3.14997335 3.44082598 3.50610057 3.12781346]\n",
      " [2.532714   3.03396691 3.53240092 3.41607153 3.47002765]]\n",
      "[INFO - 00002 ] Generating a new demonstrations from (2, 1)\n",
      "[INFO - 00003 ] Policy evaluation\n",
      "[INFO - 00003 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00003 ] Finite Policy Iteration\n",
      "[INFO - 00003 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[2.03875402 1.75198633 1.88977593 2.65410657 3.03016845]\n",
      " [1.78123988 2.64563661 3.42233835 3.99542806 3.71488141]\n",
      " [2.13963048 3.40308437 4.65636384 4.52925842 2.50893053]\n",
      " [2.99254566 4.09353063 4.06014037 2.94005089 1.80249599]\n",
      " [2.99548603 3.31227523 2.686552   1.96869111 2.14416911]]\n",
      "[INFO - 00003 ] Generating a new demonstrations from (2, 2)\n",
      "[INFO - 00004 ] Policy evaluation\n",
      "[INFO - 00004 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00004 ] Finite Policy Iteration\n",
      "[INFO - 00004 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[2.49431633 2.61866764 3.27117259 3.38457684 3.19525562]\n",
      " [2.36049616 3.68259516 4.44962583 3.96952906 4.18238257]\n",
      " [4.20120902 5.10103803 4.95178208 4.44848393 4.61787771]\n",
      " [4.44143682 4.55437714 4.86284553 4.52735907 4.54393288]\n",
      " [4.0442153  4.09442105 4.01089966 4.4977055  4.18702232]]\n",
      "[INFO - 00004 ] Generating a new demonstrations from (2, 1)\n",
      "[INFO - 00005 ] Policy evaluation\n",
      "[INFO - 00005 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00005 ] Finite Policy Iteration\n",
      "[INFO - 00005 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[4.3914221  4.14191889 3.30353853 3.70908497 3.63376832]\n",
      " [3.7090976  3.13098062 2.4262139  2.60290341 3.21010047]\n",
      " [3.11468492 3.04618579 3.54002788 2.68583532 2.30074343]\n",
      " [3.6982466  3.28347455 3.29442451 3.00969884 3.32734495]\n",
      " [4.03627383 3.54124451 3.05694973 3.0907782  3.52383255]]\n",
      "[INFO - 00005 ] Generating a new demonstrations from (0, 0)\n",
      "[INFO - 00006 ] Policy evaluation\n",
      "[INFO - 00006 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00006 ] Finite Policy Iteration\n",
      "[INFO - 00006 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[2.50674202 2.12526651 1.77730414 2.15518784 2.52360639]\n",
      " [2.25481847 2.68196317 2.69638042 2.83281736 2.63520874]\n",
      " [2.2379681  2.94865737 3.61303184 3.41718649 3.61170552]\n",
      " [2.24115379 3.30050988 3.94699504 3.51238891 2.54087151]\n",
      " [1.94738381 3.06237687 3.26780686 2.65729062 2.4715501 ]]\n",
      "[INFO - 00006 ] Generating a new demonstrations from (3, 2)\n",
      "[INFO - 00007 ] Policy evaluation\n",
      "[INFO - 00007 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00007 ] Finite Policy Iteration\n",
      "[INFO - 00007 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[2.74664104 3.08667609 3.54507495 3.41448362 3.0510002 ]\n",
      " [2.36225995 3.25628417 3.70324654 4.41278931 3.34972161]\n",
      " [3.65524709 4.41344694 4.59796719 3.88632341 2.20688102]\n",
      " [3.80820508 3.99310402 3.2755453  2.59788191 1.94471168]\n",
      " [3.93579635 2.44853138 2.01933995 1.90041913 2.24078934]]\n",
      "[INFO - 00007 ] Generating a new demonstrations from (2, 2)\n",
      "[INFO - 00008 ] Policy evaluation\n",
      "[INFO - 00008 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00008 ] Finite Policy Iteration\n",
      "[INFO - 00008 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[3.91273089 4.67999261 4.8953093  4.35535743 3.40473118]\n",
      " [4.28069198 4.25942521 4.10926787 3.93188648 3.9134785 ]\n",
      " [4.22187085 3.59052914 3.98318107 3.74689938 2.87983365]\n",
      " [3.55061203 3.77873294 3.26695772 3.52349442 3.8274501 ]\n",
      " [3.23600284 3.40546654 3.35124064 3.70066955 3.53656538]]\n",
      "[INFO - 00008 ] Generating a new demonstrations from (0, 2)\n",
      "[INFO - 00009 ] Policy evaluation\n",
      "[INFO - 00009 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00009 ] Finite Policy Iteration\n",
      "[INFO - 00009 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[4.30429404 4.63833261 4.72571508 4.78725368 4.2547552 ]\n",
      " [4.71772483 4.10732236 4.6879542  4.93252022 4.50661061]\n",
      " [4.70677886 4.99376872 5.27481689 4.92338258 4.17027047]\n",
      " [5.04472018 5.04618188 4.59231339 4.87893817 5.06019794]\n",
      " [4.15588265 3.97547997 4.41468365 5.09568041 4.96229184]]\n",
      "[INFO - 00009 ] Generating a new demonstrations from (2, 2)\n",
      "[INFO - 00010 ] Policy evaluation\n",
      "[INFO - 00010 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00010 ] Finite Policy Iteration\n",
      "[INFO - 00010 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[2.13336776 2.04839547 3.15005865 3.87845728 3.78223555]\n",
      " [1.9439718  3.33929365 4.41070737 4.85741781 4.86825791]\n",
      " [2.75976557 4.98761092 5.40646844 4.99494565 5.06064744]\n",
      " [4.0861527  4.66522551 4.50564744 4.26254268 4.10349689]\n",
      " [3.32076202 4.23295381 4.51826162 4.71953246 4.02835926]]\n",
      "[INFO - 00010 ] Generating a new demonstrations from (2, 2)\n",
      "[INFO - 00011 ] Policy evaluation\n",
      "[INFO - 00011 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00011 ] Finite Policy Iteration\n",
      "[INFO - 00011 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[4.17792475 4.76980733 5.23532881 3.52181787 3.40827331]\n",
      " [4.66269419 5.38276875 5.25287843 4.39543004 3.59624547]\n",
      " [4.05348303 4.96812541 5.3996168  5.14239789 4.18694367]\n",
      " [4.22890458 3.95118041 4.66275146 4.98750303 5.15219804]\n",
      " [4.53226177 4.24630631 3.54087539 4.81123184 4.69871654]]\n",
      "[INFO - 00011 ] Generating a new demonstrations from (2, 2)\n",
      "[INFO - 00012 ] Policy evaluation\n",
      "[INFO - 00012 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00012 ] Finite Policy Iteration\n",
      "[INFO - 00012 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[3.45572677 3.45678932 4.23039287 4.24340028 4.43891156]\n",
      " [4.50696635 5.04511172 4.59631025 5.30231227 4.64282292]\n",
      " [4.82337114 5.04552463 5.29112387 5.7048217  5.15374022]\n",
      " [3.9557579  4.76855862 4.82407084 5.44088426 5.26243135]\n",
      " [3.99483616 4.51351905 4.39444754 4.73376894 4.38867304]]\n",
      "[INFO - 00012 ] Generating a new demonstrations from (2, 3)\n",
      "[INFO - 00013 ] Policy evaluation\n",
      "[INFO - 00013 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00013 ] Finite Policy Iteration\n",
      "[INFO - 00013 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[2.81019921 2.7681489  3.48118342 3.58180601 3.73821272]\n",
      " [2.95817929 4.29747645 4.5844954  4.4779264  4.76028891]\n",
      " [3.42450527 4.70014621 5.35582543 4.7721668  4.72068221]\n",
      " [4.07539966 4.59361538 4.63165921 5.07462366 4.73028155]\n",
      " [3.93068199 4.63502449 4.01719453 4.53699422 4.17572601]]\n",
      "[INFO - 00013 ] Generating a new demonstrations from (2, 2)\n",
      "[INFO - 00014 ] Policy evaluation\n",
      "[INFO - 00014 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00014 ] Finite Policy Iteration\n",
      "[INFO - 00014 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[3.62673385 4.67188958 4.71376858 3.66246691 4.23975657]\n",
      " [3.40701341 4.15709245 3.96552811 3.86859482 4.190922  ]\n",
      " [3.20351755 3.57658791 3.9666255  4.63231724 3.8938727 ]\n",
      " [3.83117069 3.74415996 3.80423256 3.20003935 2.24496739]\n",
      " [3.57569581 2.43347458 2.30177755 2.51603368 2.51166449]]\n",
      "[INFO - 00014 ] Generating a new demonstrations from (0, 2)\n",
      "[INFO - 00015 ] Policy evaluation\n",
      "[INFO - 00015 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00015 ] Finite Policy Iteration\n",
      "[INFO - 00015 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[3.83374853 4.77154227 4.52162448 5.02089217 4.87123076]\n",
      " [3.8942195  5.09042272 5.5518417  5.49670965 5.42829387]\n",
      " [3.9316291  4.62515019 5.53184112 6.19973492 5.7729927 ]\n",
      " [4.45535906 5.30199379 5.56160761 5.99511184 5.69471088]\n",
      " [4.46150085 4.82739787 5.03083085 5.14787378 4.94321111]]\n",
      "[INFO - 00015 ] Generating a new demonstrations from (2, 3)\n",
      "[INFO - 00016 ] Policy evaluation\n",
      "[INFO - 00016 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00016 ] Finite Policy Iteration\n",
      "[INFO - 00016 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[3.98216143 4.67525729 4.53244824 4.46372793 3.74258806]\n",
      " [3.85093728 4.26874417 3.60327048 3.97234775 4.48431411]\n",
      " [4.39171424 3.93882839 4.30159457 4.7581021  4.29311295]\n",
      " [4.38847435 4.99523552 4.76149903 5.2260155  4.80423903]\n",
      " [3.98340888 4.97945058 4.64897277 4.5258829  4.40278233]]\n",
      "[INFO - 00016 ] Generating a new demonstrations from (3, 3)\n",
      "[INFO - 00017 ] Policy evaluation\n",
      "[INFO - 00017 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00017 ] Finite Policy Iteration\n",
      "[INFO - 00017 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[2.56116602 2.61117388 3.38667743 4.33914926 4.46260474]\n",
      " [2.85626789 4.10189581 4.051639   4.74492316 4.88893497]\n",
      " [3.98623322 4.52841692 5.02358904 5.16282407 5.13901674]\n",
      " [3.1759502  4.10793441 4.36726281 4.62900455 4.25074258]\n",
      " [3.58477766 4.52998232 5.10495621 5.24526411 4.47764952]]\n",
      "[INFO - 00017 ] Generating a new demonstrations from (4, 3)\n",
      "[INFO - 00018 ] Policy evaluation\n",
      "[INFO - 00018 ] Training MaxEnt IRL\n",
      "iteration: 0/50\n",
      "iteration: 5/50\n",
      "iteration: 10/50\n",
      "iteration: 15/50\n",
      "iteration: 20/50\n",
      "iteration: 25/50\n",
      "iteration: 30/50\n",
      "iteration: 35/50\n",
      "iteration: 40/50\n",
      "iteration: 45/50\n",
      "[INFO - 00018 ] Finite Policy Iteration\n",
      "[INFO - 00018 ] Request a demonstrations\n",
      "-- Values Map --\n",
      "[[4.43322293 4.7792055  4.77946197 3.87869399 3.11705936]\n",
      " [5.10613874 4.82815003 4.21817026 4.0147184  2.67387132]\n",
      " [3.69388392 4.43684621 4.05542164 3.87025367 3.35680462]\n",
      " [3.12716916 4.3887013  4.58641778 4.1521366  4.26026827]\n",
      " [3.34772253 3.89080422 4.06309385 4.34357391 4.33378589]]\n",
      "[INFO - 00018 ] Generating a new demonstrations from (1, 0)\n",
      "[INFO - 00019 ] Policy evaluation\n"
     ]
    }
   ],
   "source": [
    "# active learning setting\n",
    "args_str = \"\"\"\n",
    "--height 5\n",
    "--width 5\n",
    "--gamma 0.9\n",
    "--act_random 0.3\n",
    "--n_trajs 20\n",
    "--init_n_trajs 1\n",
    "--l_traj 5\n",
    "--learning_rate 0.01\n",
    "--n_iters 50\n",
    "--active\n",
    "--alpha 0.1\n",
    "--n_query 1\n",
    "--r_max 1\n",
    "\"\"\"\n",
    "\n",
    "args = parse_args_str(args_str)\n",
    "print(args)\n",
    "history = run_maxent_irl(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118.93969729670084"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(history[0]['values_gt'] - history['final']['values']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.74814978, 0.41140895, 0.07230791, 0.02030718, 0.02296249,\n",
       "       0.37662941, 0.15773828, 0.05626844, 0.05682953, 0.0662132 ,\n",
       "       0.12304938, 0.05927809, 0.06903575, 0.15579261, 0.27985438,\n",
       "       0.03832797, 0.05486701, 0.1383084 , 0.39280997, 0.96224466,\n",
       "       0.0271083 , 0.06422192, 0.25481293, 0.87438288, 1.78312732])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_2023spring-9SpTBrNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
